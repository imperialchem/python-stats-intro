{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32d82c26",
   "metadata": {},
   "source": [
    "\n",
    "# Part 2 - Multiple Hypothesis Testing with the Diabetes Dataset\n",
    "\n",
    "## Why do we need to care if we do multiple hypothesis testing?\n",
    "\n",
    "In Part 1, we have explored comparing 2 groups. We were able to say that they are different from each other because the p-value was below the &alpha; cut-off value we set to 0.05. In simple words, the probability of seeing the effect just at random, and not a real effect - *a false positive* or **Type 1** error - is below 5%.\n",
    "\n",
    "## Multiple hypothesis testing\n",
    "\n",
    "While doing research, comparing two groups would mean our experiment was quite simple. There is nothing wrong with that, but more often you will test multiple hypotheses at the same time.\n",
    "\n",
    "For example, you might be:\n",
    "- Testing the effect of multiple different bactericidal molecules you synthesised on bacterial survival.\n",
    "- Examining proteomics data trying to determine which ones out of thousands of protein levels are different between different growth conditions.\n",
    "- Testing whether there is a relationship between reaction yield, and time, temperature and reagent concentration(s).\n",
    "\n",
    "Basically, you will test multiple hypotheses when examining the same outcome.\n",
    "\n",
    "While asking these multiple questions, the probability of a false positive result for *each question separately* is equal to the &alpha; you set, usually 0.05.\n",
    "\n",
    "However, the probability of having *at least one false positive result while doing multiple tests* is higher. Let's take a deeper look at this potential challenge.\n",
    "\n",
    "\n",
    "## Type I Error Inflation in Multiple Testing\n",
    "When you perform multiple hypothesis tests, the probability of making at least one Type I error across all tests increases. This is because each test carries its own chance of error, and the more tests you conduct, the more likely you are to encounter a false positive.\n",
    "\n",
    "### Overall probability of at least one Type I error\n",
    "If you perform *m* tests, the overall probability of making at least one Type I error is given by:\n",
    "\n",
    "$$P(\\text{at least one Type I error}) = 1 - (1 - \\alpha)^m$$\n",
    "\n",
    "where *m* is the number of tests and &alpha; is the significance level.\n",
    "\n",
    "**Example**: For 10 tests at $\\alpha = 0.05$:\n",
    "\n",
    "$$P(\\text{at least one Type I error}) = 1 - (1 - 0.05)^{10} \\approx 0.401$$\n",
    "\n",
    "This means there's about a 40% chance of making at least one false positive when conducting 10 tests with a significance level of 0.05.\n",
    "\n",
    "The code below generates a plot showing the probability of at least Type I error depending on the number of tests done at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.05  # Significance level (Type I error rate for individual tests)\n",
    "max_tests = 100  # Maximum number of tests to simulate\n",
    "\n",
    "def probability_at_least_one_error(n_tests, alpha):\n",
    "    '''Probability of at leat one Type I error\n",
    "    when performing n_tests with alpha error rate'''\n",
    "    return 1 - (1 - alpha)**n_tests\n",
    "\n",
    "n_tests_array = arange(1, max_tests + 1)\n",
    "\n",
    "# Plot uncorrected Type I error inflation\n",
    "plot(n_tests_array,probability_at_least_one_error(n_tests_array, alpha))\n",
    "plt.title(\"Type I Error Inflation with Increasing Number of Tests (Uncorrected)\")\n",
    "plt.xlabel(\"Number of Tests\")\n",
    "plt.ylabel(\"Probability of at least one Type I error\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf8ab5",
   "metadata": {},
   "source": [
    "From this plot, you can appreciate that this probability can become quite high - almost a certainty. Fortunately, statisticians invented ways of dealing with this challenge, and minimizing the risk of false positives. We will discuss two of them.\n",
    "\n",
    "### Bonferroni Correction\n",
    "The [**Bonferroni correction**](https://en.wikipedia.org/wiki/Bonferroni_correction) adjusts the significance level to control the overall probability of making Type I errors when performing multiple tests. It divides the significance level by the number of tests to create a stricter threshold for each individual test.\n",
    "\n",
    "For *m* tests, the new significance level becomes:\n",
    "$$\\alpha_{\\text{corrected}} = \\frac{\\alpha}{m}$$\n",
    "\n",
    "**Example**: If you conduct 10 tests at $\\alpha = 0.05$, the Bonferroni correction adjusts the threshold for each test to $\\alpha_{\\text{corrected}} = 0.05 / 10 = 0.005$. This reduces the chance of making a Type I error in any given test and controls the overall error rate across all tests.\n",
    "\n",
    "### False Discovery Rate (FDR) Correction\n",
    "The [**False Discovery Rate (FDR)**](https://en.wikipedia.org/wiki/False_discovery_rate) correction provides a more flexible approach to controlling errors in multiple testing scenarios. Instead of controlling the probability of making any false positives (like the Bonferroni correction), FDR controls the expected proportion of false positives among the rejected hypotheses. This is particularly useful when conducting a large number of tests and where some false positives are tolerable, as long as their rate is controlled.\n",
    "\n",
    "The FDR is commonly controlled using the [**Benjamini-Hochberg procedure**](https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini–Hochberg_procedure), although it is not the only procedure available. The steps for this procedure are as follows:\n",
    "\n",
    "1. Rank all *p*-values in ascending order: *p<sub>1</sub>, p<sub>2</sub>, ... , p<sub>m</sub>* where *m* is the number of tests.\n",
    "2. For a chosen FDR level *q*, find the largest *k* such that:\n",
    "$$p_k \\leq \\frac{k}{m} \\cdot q$$\n",
    "3. Reject all null hypotheses with *p*-values less than or equal to *p<sub>k</sub>*.\n",
    "\n",
    "**Example**: If you perform 10 tests and choose an FDR level of $ q = 0.05 $, you rank the *p*-values and apply the above formula to determine the threshold for rejecting null hypotheses while controlling the FDR at 5%. This allows you to reject some hypotheses while ensuring that the proportion of false positives among them remains low.\n",
    "\n",
    "FDR correction is generally less conservative than Bonferroni, making it more powerful in situations where multiple comparisons are being made and some false positives are acceptable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1983387e",
   "metadata": {},
   "source": [
    "### When to Use Bonferroni vs. FDR:\n",
    "\n",
    "When to Use Bonferroni:\n",
    "\n",
    "1. Small Number of Hypotheses: Bonferroni is suitable when you’re conducting only a small number of hypothesis tests (e.g., fewer than 10). In these cases, the conservativeness of Bonferroni is less of a burden, and it ensures a low risk of false positives.\n",
    "2. Strong Control of Type I Errors: If you need to be extremely cautious about making false positives (e.g., in clinical trials or regulatory decision-making), Bonferroni is ideal. The focus is on ensuring that no false positives slip through, even if it means missing some true effects (i.e., increasing Type II errors).\n",
    "3. Confirmatory Research: When you’re in the phase of testing well-established hypotheses, where the cost of a false positive is high, Bonferroni is preferred. For example, in medical research, where a false conclusion about a drug’s efficacy could have serious consequences, Bonferroni offers a stringent level of control.\n",
    "\n",
    "When to Use FDR (False Discovery Rate):\n",
    "\n",
    "1. Large Number of Hypotheses: FDR is better suited when dealing with a large number of hypotheses, such as in genomic studies, social science research, or exploratory analyses with many comparisons. In such cases, Bonferroni might be too conservative and lead to many false negatives, missing potentially important discoveries.\n",
    "2. When Some False Positives Are Acceptable: In situations where false positives are less critical, and you’re willing to tolerate some in exchange for identifying more true positives, FDR is a more practical choice. This is often the case in preliminary research or in fields where follow-up studies can later validate the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c9b6c",
   "metadata": {},
   "source": [
    "\n",
    "## Diabetes Dataset Overview\n",
    "\n",
    "This notebook uses a subset of the **Diabetes dataset** to demonstrate multiple hypothesis testing. We will test several hypotheses about clinical measurements such as glucose levels, body mass index, and age, and their correlation with the occurence of diabetes, and then apply corrections to control for Type I errors. This dataset is often referred to as the Pima Indians Diabetes Database, as it originates from a study of diabetes among Pima Indian women in the United States.\n",
    "\n",
    "The “diabetes” dataset is commonly used in machine learning and statistical modeling for binary classification tasks, particularly for predicting the onset of diabetes. It is publicly available and often used for educational purposes or testing models. Below is a general description of the dataset:\n",
    "\n",
    "Key Variables (Features):\n",
    "\n",
    "1. Pregnancies: Number of times the patient has been pregnant.\n",
    "2. Glucose: Plasma glucose concentration after a 2-hour oral glucose tolerance test.\n",
    "3. BloodPressure: Diastolic blood pressure (mm Hg).\n",
    "4. SkinThickness: Triceps skinfold thickness (mm).\n",
    "5. Insulin: 2-Hour serum insulin (mu U/ml).\n",
    "6. BMI: Body mass index (weight in kg/(height in m)<sup>2</sup>).\n",
    "7. DiabetesPedigreeFunction: A function which scores the likelihood of diabetes based on family history (pedigree).\n",
    "8. Age: Age of the patient (years).\n",
    "9. Outcome: Binary variable (0 or 1) indicating whether the patient has diabetes (1 = Yes, 0 = No).\n",
    "\n",
    "\n",
    "## Hypothesis Testing and Errors\n",
    "In this analysis, we will try to see which variables significantly different between the diabetic and non-diabetic patients.\n",
    "Why would we do that? Each variable for which we see a significant difference could, for example, become an easy metric to monitor by doctors and be used to decide whether to send a patient for a diagnostic test to determine their diabetes status.\n",
    "\n",
    "However, if the significant difference we reveal for a variable is due to a *Type I* error (false positive), this variable would not be a good metric to be monitored.\n",
    "Therefore, we need to make sure we do not have any false positives. We'll apply both Bonferroni and False Discovery Rate (FDR) corrections to account for multiple testing and reduce Type I errors.\n",
    "\n",
    "## Data Analysis of the diabetes dataset\n",
    "\n",
    "We want to test various hypotheses about how these measurements differ between diabetic and non-diabetic individuals. We will be using the multiple test functionality from the [statsmodels](https://www.statsmodels.org/) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26170d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import scipy.stats\n",
    "import statsmodels.stats.multitest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8543ca9f",
   "metadata": {},
   "source": [
    "Loading and initial processing of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pandas.read_csv('diabetes.csv')\n",
    "\n",
    "# Replace 0 with NaN for relevant columns (we assume that 0 is invalid for certain variables)\n",
    "# We don't consider 0 as valid for 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', and 'BMI'\n",
    "columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "data[columns_with_zeros] = data[columns_with_zeros].replace(0, np.nan)\n",
    "\n",
    "# Remove incomplete data rows\n",
    "data = data.dropna()\n",
    "\n",
    "# Separate the data by the Outcome column\n",
    "diabetes_0 = data[data['Outcome'] == 0]  # No diabetes group\n",
    "diabetes_1 = data[data['Outcome'] == 1]  # Diabetes group\n",
    "\n",
    "# List of variables to plot (excluding the column, 'Outcome')\n",
    "variables = data.columns[:-1]\n",
    "\n",
    "diabetes_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363180b0",
   "metadata": {},
   "source": [
    "### Data visualisation\n",
    "\n",
    "As a first step of data analysis, let's visualise it.\n",
    "\n",
    "Plot histograms for each variable, grouped by Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a05742",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(15, 12))  # Create a figure for multiple subplots\n",
    "for i, var in enumerate(variables):\n",
    "    subplot(3, 3, i+1)  # Create a 3x3 grid of subplots\n",
    "    hrange=(min(diabetes_0[var].min(),diabetes_1[var].min()),max(diabetes_0[var].max(),diabetes_1[var].max())) #create the same range for both groups\n",
    "    diabetes_0[var].hist(bins=10,alpha=0.7,range=hrange,grid=False,label='No Diabetes')  # Plot histogram for no diabetes\n",
    "    diabetes_1[var].hist(bins=10,alpha=0.7,range=hrange,grid=False,label='Diabetes')  # Plot histogram for diabetes\n",
    "    title(var)  # Set the title to the variable name\n",
    "    legend()  # Add a legend to distinguish the groups\n",
    "\n",
    "# Display the plots\n",
    "tight_layout()  # Adjust layout to prevent overlap\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963501fd",
   "metadata": {},
   "source": [
    "We can see that for all variables the distributions for people with and without diabetes *look* different. We now want to investigate if the differences are statistically significant.\n",
    "\n",
    "### Testing if the data is nomally distributed\n",
    "\n",
    "We want first to check if the data is normally/gaussian distributed, because that will determine if we can use the t-test or not. Some of the histograms above look normally distributed, others less so, but we should use the Shapiro-Wilk test to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ccde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_0[variables].apply(scipy.stats.shapiro).iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40838d8",
   "metadata": {},
   "source": [
    "The p-value is lower than 0.05 for variables: Pregnancies, Insulin, DiabetesPedigreeFunction, Age, so we reject the null hypothesis for these variables, and infer that the distributions are not normal for these variables.\n",
    "\n",
    "How about individuals with diabetes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_1[variables].apply(scipy.stats.shapiro).iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429bfad5",
   "metadata": {},
   "source": [
    "The p-value is lower than 0.05 for variables: Insulin, DiabetesPedigreeFunction, so we reject the null hypothesis for these variables, and infer that the distributions are not normal for these variables.\n",
    "\n",
    "As some of variables are not distributed normally, we cannot use the t-test, and will use Mann-Whitney U test. Therefore, we do not need to check for equality of variance between pairs of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b554a3",
   "metadata": {},
   "source": [
    "### Hypotheses for Variables in the Diabetes Dataset\n",
    "\n",
    "1. Pregnancies:\n",
    "   - H<sub>0</sub>: The distribution of number of pregnancies is the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of number of pregnancies is different for people with and without diabetes.\n",
    "\n",
    "2. Glucose:\n",
    "   - H<sub>0</sub>: The distribution of glucose levels are the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of glucose levels are different for people with and without diabetes.\n",
    "\n",
    "3. BloodPressure:\n",
    "   - H<sub>0</sub>: The distribution of blood pressure is the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of blood pressure is different for people with and without diabetes.\n",
    "\n",
    "4. SkinThickness:\n",
    "   - H<sub>0</sub>: The distribution of skin thickness is the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of skin thickness is different for people with and without diabetes.\n",
    "\n",
    "5. Insulin:\n",
    "   - H<sub>0</sub>: The distribution of insulin levels are the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of insulin levels are different for people with and without diabetes.\n",
    "\n",
    "6. BMI:\n",
    "   - H<sub>0</sub>: The distribution of BMI is the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of BMI is different for people with and without diabetes.\n",
    "\n",
    "7. DiabetesPedigreeFunction:\n",
    "   - H<sub>0</sub>: The distribution of diabetes pedigree function is the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of diabetes pedigree function is different for people with and without diabetes.\n",
    "\n",
    "8. Age:\n",
    "   - H<sub>0</sub>: The distribution of age is the same for people with and without diabetes.\n",
    "   - H<sub>A</sub>: The distribution of age is different for people with and without diabetes.\n",
    "   \n",
    "We will first apply the Mann-Whitney U testto all variables, and make a list of the p-values of each test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = []\n",
    "\n",
    "# Perform Mann-Whitney U test for each variable\n",
    "for var in variables:\n",
    "    _, p_value = scipy.stats.mannwhitneyu(diabetes_0[var], diabetes_1[var])\n",
    "    p_values.append(p_value)\n",
    "\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72655475",
   "metadata": {},
   "source": [
    "We will now create a list of corrected p-values according to the Bonferroni and FDR criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3062b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonferroni correction\n",
    "bonferroni_corrected = statsmodels.stats.multitest.multipletests(p_values, alpha=0.05, method='bonferroni')[1]\n",
    "\n",
    "# FDR correction (Benjamini-Hochberg)\n",
    "fdr_corrected = statsmodels.stats.multitest.multipletests(p_values, alpha=0.05, method='fdr_bh')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b63dbf",
   "metadata": {},
   "source": [
    "Now print a table with all values in a nice format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57eaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"Variable\":<26} {\"p-value\":<14} {\"Bonferroni\":<15} {\"FDR\":<14}')\n",
    "for i in range(len(variables)):\n",
    "    print(f'{variables[i]:<26} {p_values[i]:<14.8f} {bonferroni_corrected[i]:<15.8f} {fdr_corrected[i]:<14.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24643f46",
   "metadata": {},
   "source": [
    "By carefully looking at the table, we can see that:\n",
    "- The p-value for the comparison of glucose levels between the diabetic and non-diabetic populations increases over the 0.05 treshold after the Bonferroni correction, but not FDR correction\n",
    "-  The p-value for the comparison of BMI between the diabetic and non-diabetic populations p-value increases over the 0.05 treshold after the Bonferroni correction, and the FDR correction.\n",
    "\n",
    "We can also visualise these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed201d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(8, 8))\n",
    "\n",
    "plot(p_values, color='blue',linestyle='',marker='o',label='Original p-values')\n",
    "plot(bonferroni_corrected, color='green',linestyle='',marker='o',label='Bonferroni corrected')\n",
    "plot(fdr_corrected, color='red',linestyle='',marker='o',label='FDR corrected')\n",
    "\n",
    "# Draw the significance cutoff at p = 0.05\n",
    "axhline(y=0.05, color='gray', linestyle='--', label='0.05 Significance cutoff')\n",
    "\n",
    "xlabel('Variables')\n",
    "ylabel('p-values')\n",
    "title('Original and Adjusted p-values')\n",
    "legend(loc='upper center')\n",
    "xticks(arange(len(variables)),variables,rotation=90)\n",
    "yticks(arange(0, 1.05, 0.05))  # Set x-axis ticks every 0.05\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f5c31",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Based on the statistical tests performed using the **Mann-Whitney U test**, we found significant differences in the distributions between people with and without diabetes for some of the variables considered. However, because we know about the increase of the probability of type I errors (false positives) as the number of tests increase, i.e. the possibility that for at least one test we wrongly reject the null hypothesis and conclude that a given variable presents a different distribution for diabetic and healthy people, we applied a correction to our p-value.\n",
    "\n",
    "When selecting people to be further diagnosed for diabetes, we want to hit a balance between sending too many people who are not sick, but more importantly - sending everyone who might be sick. Therefore, we will use the less strict procedure of excluding false positives - FDR. If we used Bonferroni correction, we might exclude people worth testing in this case.\n",
    "\n",
    "Using the FDR-corrected results, we conclude:\n",
    "\n",
    "1. **Glucose**: The distribution of glucose levels is significantly different between people with and without diabetes.\n",
    "\n",
    "2. **Insulin**: The distribution of insulin levels is significantly different between people with and without diabetes.\n",
    "\n",
    "3. **Age**: The distribution of age is significantly different between people with and without diabetes.\n",
    "\n",
    "For all other variables considered in this analysis we could not find a significant difference. That does not mean the difference does not exist - perhaps it is just that our data is not sufficient to show it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b6d4d2",
   "metadata": {},
   "source": [
    "### Practice - Analysis of the full diabetes dataset\n",
    "\n",
    "In the study we conducted above, we concluded that for several variables the corrected p-values were not sufficiently low to reject the null hypothesis, and we could not conclude that there is a significant difference between the groups with diabetes and without diabetes in spite of some apparent differences in the histograms. However, with more data, it may be possible to show that such differences are actually statistically significant.\n",
    "\n",
    "The dataset explored above was just a subset of the full diabetes dataset. You can use the full dataset in the *diabetes_full.csv* file, to investigate if using more data you are able to prove that other variables show significant differences between diabetic and non-diabetic populations, and thus may be used to aid in diagnostic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
